

# ğŸš€ LATAM Airlines DevSecOps/SRE Challenge

## âœ¨ DescripciÃ³n del Proyecto
Este proyecto implementa un sistema en la nube para ingestar, almacenar y exponer datos a travÃ©s de una API HTTP para que puedan ser consumidos por terceros, utilizando infraestructura como cÃ³digo (IaC) con Terraform y flujos de CI/CD con GitHub Actions. AdemÃ¡s, se incorporaron pruebas de integraciÃ³n, carga, monitoreo y propuestas de alertas para garantizar la resiliencia y escalabilidad del sistema.

---

## ğŸ—ï¸ Parte 1: Infraestructura e IaC

### **1. Identificar la infraestructura necesaria para ingestar, almacenar y exponer datos**

#### **1.1 Ingesta, almacenamiento y exposiciÃ³n de datos**

##### **1.1.a Utilizar el esquema Pub/Sub para ingesta de datos**
El sistema implementa un esquema de mensajerÃ­a asÃ­ncrona utilizando **Google Cloud Pub/Sub** para garantizar la ingesta eficiente de datos. La arquitectura incluye:

- **TÃ³pico:** `datos-topic`
  - Este tÃ³pico recibe los mensajes publicados por el sistema o usuarios externos.
  - Ejemplo de mensaje publicado:
    ```json
    {
      "id": "123",
      "contenido": "Este es un mensaje de prueba",
      "timestamp": "2025-01-14T10:00:00Z"
    }
    ```

- **SuscripciÃ³n:** `datos-subscription`
  - Procesa los mensajes del tÃ³pico y envÃ­a los datos para su almacenamiento en BigQuery.

**Ventajas del esquema Pub/Sub:**
- Desacopla la producciÃ³n y el consumo de datos, lo que facilita la escalabilidad.
- Proporciona resiliencia ante fallos temporales.
- Admite altos volÃºmenes de datos de manera eficiente.

##### **1.1.b Base de datos para el almacenamiento enfocado en analÃ­tica de datos**
Se utiliza **Google BigQuery** como base de datos principal para almacenar los datos. 

- **Dataset:** `latam_dataset`
- **Tabla:** `datos`
  - Esquema definido:
    ```json
    [
      {
        "name": "id",
        "type": "STRING",
        "mode": "REQUIRED",
        "description": "Identificador Ãºnico del dato"
      },
      {
        "name": "contenido",
        "type": "STRING",
        "mode": "NULLABLE",
        "description": "Contenido del dato"
      },
      {
        "name": "timestamp",
        "type": "TIMESTAMP",
        "mode": "REQUIRED",
        "description": "Marca de tiempo del registro"
      }
    ]
    ```

**Beneficios de BigQuery:**
- Es ideal para tareas analÃ­ticas debido a su alta velocidad de consulta.
- Escalabilidad automÃ¡tica para grandes volÃºmenes de datos.
- FÃ¡cil integraciÃ³n con otros servicios de GCP.

##### **1.1.c Endpoint HTTP para servir parte de los datos almacenados**
Se implementÃ³ una API utilizando **FastAPI** desplegada en **Google Cloud Run**. Esta API expone los datos almacenados en BigQuery y ofrece dos endpoints principales:

- **Endpoint `/health`:** 
  - Devuelve el estado del sistema.
  - Ejemplo de respuesta:
    ```json
    {
      "status": "ok"
    }
    ```

- **Endpoint `/datos`:**
  - Devuelve los Ãºltimos 10 registros almacenados en BigQuery.
  - Ejemplo de respuesta:
    ```json
    {
      "datos": [
        {
          "id": "789",
          "contenido": "Prueba automÃ¡tica",
          "timestamp": "2024-01-14T14:00:00+00:00"
        }
      ]
    }
    ```

---

#### **1.2 Deployar infraestructura mediante Terraform**

Se utilizÃ³ **Terraform** para automatizar la creaciÃ³n y gestiÃ³n de la infraestructura en Google Cloud Platform. Los recursos desplegados incluyen:

- **Google Cloud Pub/Sub:**
  - TÃ³pico: `datos-topic`
  - SuscripciÃ³n: `datos-subscription`

- **Google BigQuery:**
  - Dataset: `latam_dataset`
  - Tabla: `datos`

- **Google Cloud Run:**
  - API desplegada para exposiciÃ³n de datos.

---
## ğŸ”„ Parte 2: Aplicaciones y flujo CI/CD

### **2.1 API HTTP**

La API HTTP fue desarrollada utilizando **FastAPI** para garantizar un alto rendimiento y facilidad de implementaciÃ³n. Los endpoints principales permiten la exposiciÃ³n de datos almacenados en la base de datos.

#### **Endpoints implementados:**
- **GET `/health`:** 
  - Verifica la salud de la API y confirma que estÃ¡ operativa.
  - **Respuesta de ejemplo:**
    ```json
    {
      "status": "ok"
    }
    ```

- **GET `/datos`:**
  - Recupera los Ãºltimos registros almacenados en **Google BigQuery**.
  - **Respuesta de ejemplo:**
    ```json
    {
      "datos": [
        {
          "id": "789",
          "contenido": "Prueba automÃ¡tica",
          "timestamp": "2024-01-14T14:00:00+00:00"
        }
      ]
    }
    ```

**LÃ³gica implementada:**
- ConexiÃ³n directa con **Google BigQuery** utilizando su cliente oficial de Python.
- Queries optimizadas para limitar los resultados y garantizar baja latencia.

---

### **2.2 Deployar API HTTP mediante CI/CD**

El despliegue de la API HTTP se realiza utilizando un flujo de **CI/CD con GitHub Actions**. Este pipeline automatiza los pasos de construcciÃ³n, prueba y despliegue en **Google Cloud Run**.

#### **2.2.1 Flujo del pipeline CI/CD:**
1. **Build Docker Image:**
   - ConstrucciÃ³n de la imagen Docker de la API.
   - Push de la imagen a **Google Container Registry (GCR)**.

2. **Deploy con Terraform:**
   - Terraform aplica los cambios para actualizar la infraestructura, incluyendo el despliegue de la API en **Google Cloud Run**.

3. **Pruebas AutomÃ¡ticas:**
   - Pruebas de integraciÃ³n y carga para validar los endpoints `/health` y `/datos`.

##### **Archivo GitHub Actions (`.github/workflows/deploy.yml`):**


### ğŸ“¦ Evidencias
- Pipeline exitoso: Logs de GitHub Actions.
https://github.com/fernachbauer/latam-challenge/actions/runs/12771103343

---
### **2.3 (Opcional) Ingesta de datos desde Pub/Sub**

En esta etapa opcional, se implementÃ³ una lÃ³gica para procesar los mensajes recibidos en **Google Cloud Pub/Sub** y almacenarlos en la base de datos **Google BigQuery**.

#### **Objetivo:**
- Configurar una suscripciÃ³n a **Pub/Sub** que permita:
  1. Recibir mensajes publicados en el tÃ³pico `datos-topic`.
  2. Procesar y validar los datos.
  3. Almacenar los datos recibidos en la tabla `datos` del dataset `latam_dataset` en **BigQuery**.


#### **Flujo del procesamiento:**

1. **PublicaciÃ³n de datos:**
   - Los datos son enviados al tÃ³pico `datos-topic` mediante el cliente de **Pub/Sub**.

2. **Procesamiento de mensajes:**
   - Se configura la suscripciÃ³n `datos-subscription` para recibir los mensajes del tÃ³pico.
   - Los mensajes son procesados a travÃ©s de un **callback** que:
     - Decodifica y valida los datos.
     - Inserta los registros en la tabla de **BigQuery**.

3. **InserciÃ³n en BigQuery:**
   - Los datos se insertan en la tabla `datos`, aprovechando las capacidades de la API de BigQuery.

#### Ventajas de esta implementaciÃ³n:
- **Escalabilidad:** Pub/Sub maneja un alto volumen de mensajes.
- **Flexibilidad:** Los datos malformados pueden ser gestionados en el callback.
- **IntegraciÃ³n serverless:** La combinaciÃ³n de Pub/Sub y BigQuery simplifica la operaciÃ³n.

#### **Evidencias:**
Mensajes enviados a Pub/Sub:

gcloud pubsub topics publish datos-topic \
  --message '{"id":"123","contenido":"Mensaje de prueba","timestamp":"2025-01-14T12:00:00Z"}'

messageIds:
- '13531497031954997'
---
### **2.4 Diagrama de Arquitectura:**
- https://drive.google.com/file/d/1XTSk-mBAVAPTKsSG6DKX_VgDACknp_h8/view?usp=sharing

#### Infraestructura Propuesta

1. **Ingesta de Datos (Google Cloud Pub/Sub)**

Componentes:
- TÃ³pico (datos-topic): Recibe los datos enviados por los productores.
- SuscripciÃ³n (datos-subscription): Entrega los mensajes a los consumidores.

RazÃ³n: Desacopla productores y consumidores, garantiza entrega de mensajes y escala automÃ¡ticamente.

2. **Almacenamiento de Datos (Google BigQuery)**

Componentes:
- Dataset (latam_dataset): Contiene la tabla datos.
- Tabla (datos): Almacena los datos con un esquema analÃ­tico optimizado.

RazÃ³n: BigQuery es ideal para consultas rÃ¡pidas y escalables en grandes volÃºmenes de datos.

3. **ExposiciÃ³n de Datos (FastAPI en Google Cloud Run)**

Componentes:
- FastAPI: API con endpoints /health y /datos.
- Cloud Run: Despliega la API como un contenedor serverless.

RazÃ³n: Cloud Run escala automÃ¡ticamente segÃºn la demanda, optimizando costos y garantizando disponibilidad.

4. **CI/CD con GitHub Actions**

Pipeline:
- ConstrucciÃ³n y despliegue de contenedores Docker.
- Infraestructura gestionada con Terraform.
- Pruebas de integraciÃ³n y carga automÃ¡ticas.

RazÃ³n: AutomatizaciÃ³n completa para garantizar calidad y despliegues consistentes.

**Resumen del Proceso**
PublicaciÃ³n de Datos: Los datos ingresan a travÃ©s de Pub/Sub.
Procesamiento: Se validan y almacenan en BigQuery.
Consumo: Los datos se exponen mediante una API HTTP desplegada en Cloud Run.
AutomatizaciÃ³n: CI/CD gestiona el flujo completo desde cÃ³digo hasta producciÃ³n.

---

## ğŸ§ª **Parte 3: Pruebas de IntegraciÃ³n y Puntos CrÃ­ticos de Calidad**

### **3.1 Implementar en el flujo CI/CD un test de integraciÃ³n que verifique que la API efectivamente estÃ¡ exponiendo los datos de la base de datos. ArgumentaciÃ³n.**

- **DescripciÃ³n**: Se incluyÃ³ un test de integraciÃ³n que valida si el endpoint `/datos` retorna datos almacenados en BigQuery.
- **Objetivo**: Garantizar que la API HTTP funcione correctamente y exponga los datos como se espera.
- **ImplementaciÃ³n**: Los tests se ejecutan automÃ¡ticamente en el pipeline CI/CD, aprovechando GitHub Actions.
- **CÃ³digo de tests**: /latam-challenge/tests/integration/test_api.py
```python
  def test_health_endpoint():
    response = requests.get(f"{BASE_URL}/health")
    assert response.status_code == 200
    assert response.json() == {"status": "ok"}
    
def test_datos_endpoint():
    response = requests.get(f"{BASE_URL}/datos")
    assert response.status_code == 200
    assert "datos" in response.json()
```
- **JustificaciÃ³n:**
Este test asegura que la conexiÃ³n entre la API y BigQuery estÃ© configurada correctamente.
AdemÃ¡s, se verifica la estructura y contenido de la respuesta de la API.

https://github.com/fernachbauer/latam-challenge/actions/runs/12771103343/job/35597552427
Run pytest tests/

============================= test session starts ==============================
platform linux -- Python 3.9.21, pytest-8.3.4, pluggy-1.5.0
rootdir: /home/runner/work/latam-challenge/latam-challenge
plugins: anyio-4.8.0
collected 2 items

tests/integration/test_api.py ..                                         [100%]

============================== 2 passed in 1.09s ===============================
---
### **3.2 Proponer otras pruebas de integraciÃ³n que validen que el sistema estÃ¡ funcionando correctamente y cÃ³mo se implementarÃ­an**

* **Test de Ingesta de Datos:**

**DescripciÃ³n:** Validar que los datos publicados en Pub/Sub se almacenen correctamente en BigQuery.

**ImplementaciÃ³n propuesta:**
- Simular la publicaciÃ³n de un mensaje en el tÃ³pico datos-topic.
- Confirmar que los datos aparezcan en la tabla datos de BigQuery.

* **Test de validaciÃ³n de mensajes:**

**DescripciÃ³n:** Verificar que los mensajes malformados enviados a Pub/Sub no se almacenen en BigQuery.

ImplementaciÃ³n propuesta:
- Enviar un mensaje con formato incorrecto al tÃ³pico.
- Asegurar que no aparece en la tabla datos.

* **Test de Endpoint /health con Dependencias Externas:**

**DescripciÃ³n:** Verificar que el endpoint /health no solo confirma la disponibilidad de la API, sino tambiÃ©n la conectividad con servicios externos como BigQuery.

**CÃ³digo Ejemplo:**
```python
def test_health_with_dependencies():
    response = requests.get(f"{BASE_URL}/health")
    assert response.status_code == 200
    assert response.json() == {"status": "ok"}
    
    # Validar conectividad con BigQuery
    try:
        query = "SELECT 1"
        query_job = bigquery_client.query(query)
        assert query_job.result()
    except Exception as e:
        assert False, f"Error de conectividad con BigQuery: {e}"
```
---
### 3.3. âš ï¸ Puntos CrÃ­ticos Identificados y Pruebas de Rendimiento

ğŸ“‰ **Posibles Puntos CrÃ­ticos:**

1. **Latencia en consultas a BigQuery:**  
   - Bajo cargas elevadas, las consultas a BigQuery presentan tiempos de respuesta variables.  
   - **Pruebas de carga** revelaron que la latencia promedio llegÃ³ hasta **~600ms**, superando el umbral Ã³ptimo.

2. **Errores de ingesta de datos por formatos invÃ¡lidos:**  
   - La ausencia de validaciÃ³n previa de los datos provenientes de **Pub/Sub** podrÃ­a derivar en errores al insertar registros en **BigQuery**.

3. **Sobrecarga de la API bajo alta demanda:**  
   - Las pruebas de carga mostraron que el endpoint `/datos` maneja correctamente mÃºltiples solicitudes **GET**, pero:
     - El sistema registrÃ³ un **11.98% de fallos** en intentos de inserciÃ³n (**POST**) por falta de implementaciÃ³n de dicho endpoint.  
     - La latencia aumentÃ³ progresivamente, alcanzando picos de hasta **6 segundos** bajo carga continua.  
     - La **saturaciÃ³n** de recursos limitÃ³ la capacidad de respuesta eficiente.

ğŸ“ˆ **Pruebas de Carga Implementadas:**

Se utilizÃ³ **Locust** para evaluar el rendimiento del sistema:

https://github.com/fernachbauer/latam-challenge/actions/runs/12771103343/job/35597552427

- **Usuarios concurrentes:** 50  
- **Tasa de incremento:** 10 usuarios/segundo  
- **DuraciÃ³n:** 2 minutos  

ğŸ“„ **Resultados clave:**

- âœ… **GET /datos:** RespondiÃ³ exitosamente con una latencia promedio aceptable de **400ms**.  
- âŒ **POST /datos:** El 100% de los intentos fallaron con error **405** (**Method Not Allowed**), evidenciando la **ausencia de un endpoint de ingesta directa**.  
- ğŸ“‰ **Latencia creciente:** Se detectÃ³ un crecimiento sostenido en los tiempos de respuesta, alcanzando **hasta 6 segundos** en momentos crÃ­ticos.

ğŸ” **Conclusiones:**

- La API soporta cargas moderadas para **lectura**, pero **no escala adecuadamente** bajo alta demanda sostenida.  
- La falta de un endpoint para inserciÃ³n directa limita el flujo de ingesta eficiente.  
- La latencia creciente podrÃ­a afectar la experiencia del usuario final y generar **timeouts** en sistemas integrados.

ğŸ’¡ **Acciones Correctivas:**

1. **Optimizar consultas a BigQuery:**  
   - Implementar **particiones** y **clustering** para mejorar el tiempo de respuesta.  

2. **Implementar validaciÃ³n de datos en la ingesta:**  
   - Prevenir fallos de inserciÃ³n mediante validaciones estrictas antes de enviar datos a BigQuery.

3. **Incorporar balanceo de carga y autoescalado:**  
   - Desplegar instancias adicionales de la API en **Cloud Run** bajo demanda.  
   - Configurar balanceo de carga para distribuir el trÃ¡fico eficientemente.  

4. **Agregar el endpoint POST /datos:**  
   - Permitir la ingesta directa de datos y evitar sobrecargar el flujo Pub/Sub.
---

## **3.4 Proponer cÃ³mo robustecer tÃ©cnicamente el sistema para compensar o solucionar dichos puntos crÃ­ticos**

### **OptimizaciÃ³n de Consultas en BigQuery:**

- Usar particiones y clustering para mejorar el rendimiento de las consultas.
- Limitar el nÃºmero de registros retornados.

### **ValidaciÃ³n de Mensajes en Pub/Sub:**

- Implementar lÃ³gica de validaciÃ³n en el suscriptor antes de insertar datos en BigQuery.
- Registrar errores en un sistema de monitoreo para su anÃ¡lisis.

### **Autoescalado y Balanceo de Carga:**

- Configurar Cloud Run para escalar automÃ¡ticamente con base en las mÃ©tricas de latencia o CPU.
- Utilizar un balanceador de carga para distribuir el trÃ¡fico de manera eficiente.

### **Monitoreo y Alertas:**

- Usar Google Cloud Monitoring para rastrear mÃ©tricas clave como:
    * Latencia en BigQuery.
    * Errores en Pub/Sub.
    * Tiempo de respuesta de la API.
- Configurar alertas basadas en lÃ­mites crÃ­ticos (p. ej., latencia > 1s).

---
## ğŸ“Š **Parte 4: MÃ©tricas y Monitoreo**

### **4.1 Proponer 3 mÃ©tricas crÃ­ticas para entender la salud y rendimiento del sistema end-to-end**

1. **ğŸš€ Tasa de Ingesta de Mensajes en Pub/Sub (Messages Published Rate)**  
   - **DescripciÃ³n:** NÃºmero de mensajes publicados por segundo/minuto en el tÃ³pico `datos-topic`.  
   - **Objetivo:** Detectar cuellos de botella en la ingesta de datos.  

2. **â±ï¸ Latencia de Respuesta de la API (API Response Latency)**  
   - **DescripciÃ³n:** Tiempo promedio de respuesta del endpoint `/datos` y `/health`.  
   - **Objetivo:** Identificar degradaciÃ³n en el rendimiento de la API bajo diferentes cargas.  

3. **âŒ Tasa de Errores de Ingesta (Error Rate in Data Ingestion)**  
   - **DescripciÃ³n:** Porcentaje de mensajes fallidos al ser insertados desde Pub/Sub a BigQuery.  
   - **Objetivo:** Detectar problemas en el procesamiento de datos y prevenir pÃ©rdida de informaciÃ³n.  

---

### **4.2 Proponer una herramienta de visualizaciÃ³n y describe textualmente quÃ© mÃ©tricas mostrarÃ­a**

**ğŸ” Herramienta Propuesta:** *Google Cloud Monitoring (Stackdriver)*

**ğŸ“Š MÃ©tricas a visualizar:**

- **Tasa de Ingesta de Mensajes (Pub/Sub):** GrÃ¡fica de lÃ­neas que muestra la cantidad de mensajes procesados por segundo.  
- **Latencia de Respuesta de la API:** Panel con tiempos de respuesta promedio, mÃ¡ximo y percentiles.  
- **Errores de BigQuery:** Conteo de errores de inserciÃ³n de datos, diferenciando entre errores transitorios y crÃ­ticos.  
- **Uso de Recursos (CPU/RAM):** Estado de utilizaciÃ³n de recursos de Cloud Run.  

**ğŸ“ˆ Â¿CÃ³mo ayuda esta informaciÃ³n?**  
- **Rendimiento:** Detectar cuellos de botella y optimizar recursos.  
- **Estabilidad:** Identificar picos de latencia y prevenir fallos en la API.  
- **Disponibilidad:** Asegurar la ingesta continua de datos y reacciÃ³n ante errores crÃ­ticos.  

---

## **4.3 ImplementaciÃ³n de la herramienta de monitoreo en la nube**

**ğŸ”§ Pasos de ImplementaciÃ³n:**

1. **Activar Cloud Monitoring:**  
   - Configurar Google Cloud Monitoring para recolectar mÃ©tricas de Pub/Sub, Cloud Run y BigQuery.  

2. **Configurar ExportaciÃ³n de Logs:**  
   - Exportar logs de errores y mÃ©tricas de Pub/Sub a Cloud Monitoring.  

3. **Crear Dashboards Personalizados:**  
   - DiseÃ±ar paneles interactivos con grÃ¡ficos de lÃ­neas, indicadores y tablas.  

4. **Configurar Alertas AutomÃ¡ticas:**  
   - Definir umbrales para alertas crÃ­ticas (e.g., latencia > 1s, error rate > 5%).  

---

## **4.4 Escalamiento de la soluciÃ³n a 50 sistemas similares**

**ğŸ”„ Cambios en la VisualizaciÃ³n:**

- **SegmentaciÃ³n por Proyecto/Sistema:** Agrupar mÃ©tricas por cada instancia del sistema.  
- **Dashboard Global:** Vista consolidada para todas las instancias, destacando los sistemas crÃ­ticos.  
- **MÃ©tricas Agregadas:**  
  - Tasa de ingesta global vs. individual.  
  - Latencia promedio global.  
  - Comparativa de errores entre sistemas.  

**ğŸ”“ Nuevas MÃ©tricas Desbloqueadas:**  
- **Balanceo de carga entre sistemas.**  
- **Uso de red entre regiones.**  
- **DistribuciÃ³n geogrÃ¡fica de usuarios y trÃ¡fico.**  

---

## **4.5 Dificultades o limitaciones en observabilidad por problemas de escalabilidad**

**âš ï¸ Riesgos Potenciales:**

1. **Sobrecarga de Monitoreo:**  
   - Aumento en costos por almacenamiento de logs y mÃ©tricas.  
   - SaturaciÃ³n de dashboards con exceso de datos.  

2. **Falsos Positivos en Alertas:**  
   - Umbrales mal configurados pueden generar alertas innecesarias.  

3. **FragmentaciÃ³n de InformaciÃ³n:**  
   - Dificultad para correlacionar mÃ©tricas si no se estandariza la recolecciÃ³n de datos.  

**ğŸ› ï¸ Propuestas de MitigaciÃ³n:**  
- **Uso de mÃ©tricas agregadas:** Consolidar datos para obtener insights globales.  
- **Optimizar reglas de alertas:** Definir umbrales dinÃ¡micos ajustados al contexto.  
- **Automatizar escalamiento:** Implementar autoescalado basado en mÃ©tricas crÃ­ticas.



---

# ğŸ‰ **Â¡Gracias por la Oportunidad!** ğŸ™Œ

Quiero expresar mi mÃ¡s sincero agradecimiento por la oportunidad de participar en el **LATAM Airlines DevSecOps/SRE Challenge**. ğŸŒâœˆï¸

Muchas gracias por recibir mi desafÃ­o, en el van muchas horas de esfuerzo y motivaciÃ³n por la oportunidad de formar parte del equipo.

Este proyecto ha sido una experiencia increÃ­ble, en la que he invertido muchas horas llenas de **motivaciÃ³n**, **aprendizaje** e **ilusiÃ³n**. Cada lÃ­nea de cÃ³digo, cada despliegue y cada prueba fueron pensados con el compromiso de entregar una soluciÃ³n robusta ,a la altura del desafÃ­o y la compaÃ±ia. ğŸ’» âœˆï¸âœˆï¸âœˆï¸âœˆï¸âœˆï¸âœˆï¸

Â¡Estoy emocionado por todo lo aprendido y por seguir creciendo en el mundo de la tecnologÃ­a! ğŸŒ

---

## ğŸ”§âœ¨âœˆï¸ **Â¡Nos vemos en las nubes!** â˜ï¸
           |
                       --====|====--
                             |  

                         .-"""""-. 
                       .'_________'. 
                      /_/_|__|__|_\_\
                     ;'-._       _.-';
,--------------------|    `-. .-'    |--------------------,
 ``""--..__    ___   ;       '       ;   ___    __..--""``
  jgs      `"-// \\.._\             /_..// \\-"`
              \\_//    '._       _.'    \\_//
               `"`        ``---``        `"`

ğŸ“‚ Repositorio
ğŸ”— https://github.com/fernachbauer/latam-challenge

ğŸ“§ Contacto
Nombre: Fernando Nachbauer R
Correo: fernachbauer@gmail.com