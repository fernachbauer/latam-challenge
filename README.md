

# üöÄ LATAM Airlines DevSecOps/SRE Challenge

## ‚ú® Descripci√≥n del Proyecto
Este proyecto implementa un sistema en la nube para ingestar, almacenar y exponer datos a trav√©s de una API HTTP para que puedan ser consumidos por terceros, utilizando infraestructura como c√≥digo (IaC) con Terraform y flujos de CI/CD con GitHub Actions. Adem√°s, se incorporaron pruebas de integraci√≥n, carga, monitoreo y propuestas de alertas para garantizar la resiliencia y escalabilidad del sistema.

---

## üèóÔ∏è Parte 1: Infraestructura e IaC

### **1. Identificar la infraestructura necesaria para ingestar, almacenar y exponer datos**

#### **1.1 Ingesta, almacenamiento y exposici√≥n de datos**

##### **1.1.a Utilizar el esquema Pub/Sub para ingesta de datos**
El sistema implementa un esquema de mensajer√≠a as√≠ncrona utilizando **Google Cloud Pub/Sub** para garantizar la ingesta eficiente de datos. La arquitectura incluye:

- **T√≥pico:** `datos-topic`
  - Este t√≥pico recibe los mensajes publicados por el sistema o usuarios externos.
  - Ejemplo de mensaje publicado:
    ```json
    {
      "id": "123",
      "contenido": "Este es un mensaje de prueba",
      "timestamp": "2025-01-14T10:00:00Z"
    }
    ```

- **Suscripci√≥n:** `datos-subscription`
  - Procesa los mensajes del t√≥pico y env√≠a los datos para su almacenamiento en BigQuery.

**Ventajas del esquema Pub/Sub:**
- Desacopla la producci√≥n y el consumo de datos, lo que facilita la escalabilidad.
- Proporciona resiliencia ante fallos temporales.
- Admite altos vol√∫menes de datos de manera eficiente.

##### **1.1.b Base de datos para el almacenamiento enfocado en anal√≠tica de datos**
Se utiliza **Google BigQuery** como base de datos principal para almacenar los datos. 

- **Dataset:** `latam_dataset`
- **Tabla:** `datos`
  - Esquema definido:
    ```json
    [
      {
        "name": "id",
        "type": "STRING",
        "mode": "REQUIRED",
        "description": "Identificador √∫nico del dato"
      },
      {
        "name": "contenido",
        "type": "STRING",
        "mode": "NULLABLE",
        "description": "Contenido del dato"
      },
      {
        "name": "timestamp",
        "type": "TIMESTAMP",
        "mode": "REQUIRED",
        "description": "Marca de tiempo del registro"
      }
    ]
    ```

**Beneficios de BigQuery:**
- Es ideal para tareas anal√≠ticas debido a su alta velocidad de consulta.
- Escalabilidad autom√°tica para grandes vol√∫menes de datos.
- F√°cil integraci√≥n con otros servicios de GCP.

##### **1.1.c Endpoint HTTP para servir parte de los datos almacenados**
Se implement√≥ una API utilizando **FastAPI** desplegada en **Google Cloud Run**. Esta API expone los datos almacenados en BigQuery y ofrece dos endpoints principales:

- **Endpoint `/health`:** 
  - Devuelve el estado del sistema.
  - Ejemplo de respuesta:
    ```json
    {
      "status": "ok"
    }
    ```

- **Endpoint `/datos`:**
  - Devuelve los √∫ltimos 10 registros almacenados en BigQuery.
  - Ejemplo de respuesta:
    ```json
    {
      "datos": [
        {
          "id": "789",
          "contenido": "Prueba autom√°tica",
          "timestamp": "2024-01-14T14:00:00+00:00"
        }
      ]
    }
    ```

---

#### **1.2 Deployar infraestructura mediante Terraform**

Se utiliz√≥ **Terraform** para automatizar la creaci√≥n y gesti√≥n de la infraestructura en Google Cloud Platform. Los recursos desplegados incluyen:

- **Google Cloud Pub/Sub:**
  - T√≥pico: `datos-topic`
  - Suscripci√≥n: `datos-subscription`

- **Google BigQuery:**
  - Dataset: `latam_dataset`
  - Tabla: `datos`

- **Google Cloud Run:**
  - API desplegada para exposici√≥n de datos.

---
## üîÑ Parte 2: Aplicaciones y flujo CI/CD

### **2.1 API HTTP**

La API HTTP fue desarrollada utilizando **FastAPI** para garantizar un alto rendimiento y facilidad de implementaci√≥n. Los endpoints principales permiten la exposici√≥n de datos almacenados en la base de datos.

#### **Endpoints implementados:**
- **GET `/health`:** 
  - Verifica la salud de la API y confirma que est√° operativa.
  - **Respuesta de ejemplo:**
    ```json
    {
      "status": "ok"
    }
    ```

- **GET `/datos`:**
  - Recupera los √∫ltimos registros almacenados en **Google BigQuery**.
  - **Respuesta de ejemplo:**
    ```json
    {
      "datos": [
        {
          "id": "789",
          "contenido": "Prueba autom√°tica",
          "timestamp": "2024-01-14T14:00:00+00:00"
        }
      ]
    }
    ```

**L√≥gica implementada:**
- Conexi√≥n directa con **Google BigQuery** utilizando su cliente oficial de Python.
- Queries optimizadas para limitar los resultados y garantizar baja latencia.

---

### **2.2 Deployar API HTTP mediante CI/CD**

El despliegue de la API HTTP se realiza utilizando un flujo de **CI/CD con GitHub Actions**. Este pipeline automatiza los pasos de construcci√≥n, prueba y despliegue en **Google Cloud Run**.

#### **2.2.1 Flujo del pipeline CI/CD:**
1. **Build Docker Image:**
   - Construcci√≥n de la imagen Docker de la API.
   - Push de la imagen a **Google Container Registry (GCR)**.

2. **Deploy con Terraform:**
   - Terraform aplica los cambios para actualizar la infraestructura, incluyendo el despliegue de la API en **Google Cloud Run**.

3. **Pruebas Autom√°ticas:**
   - Pruebas de integraci√≥n y carga para validar los endpoints `/health` y `/datos`.

##### **Archivo GitHub Actions (`.github/workflows/deploy.yml`):**


### üì¶ Evidencias
- Pipeline exitoso: Logs de GitHub Actions.
https://github.com/fernachbauer/latam-challenge/actions/runs/12771103343

---
### **2.3 (Opcional) Ingesta de datos desde Pub/Sub**

En esta etapa opcional, se implement√≥ una l√≥gica para procesar los mensajes recibidos en **Google Cloud Pub/Sub** y almacenarlos en la base de datos **Google BigQuery**.

#### **Objetivo:**
- Configurar una suscripci√≥n a **Pub/Sub** que permita:
  1. Recibir mensajes publicados en el t√≥pico `datos-topic`.
  2. Procesar y validar los datos.
  3. Almacenar los datos recibidos en la tabla `datos` del dataset `latam_dataset` en **BigQuery**.


#### **Flujo del procesamiento:**

1. **Publicaci√≥n de datos:**
   - Los datos son enviados al t√≥pico `datos-topic` mediante el cliente de **Pub/Sub**.

2. **Procesamiento de mensajes:**
   - Se configura la suscripci√≥n `datos-subscription` para recibir los mensajes del t√≥pico.
   - Los mensajes son procesados a trav√©s de un **callback** que:
     - Decodifica y valida los datos.
     - Inserta los registros en la tabla de **BigQuery**.

3. **Inserci√≥n en BigQuery:**
   - Los datos se insertan en la tabla `datos`, aprovechando las capacidades de la API de BigQuery.

#### Ventajas de esta implementaci√≥n:
- **Escalabilidad:** Pub/Sub maneja un alto volumen de mensajes.
- **Flexibilidad:** Los datos malformados pueden ser gestionados en el callback.
- **Integraci√≥n serverless:** La combinaci√≥n de Pub/Sub y BigQuery simplifica la operaci√≥n.

#### **Evidencias:**
Mensajes enviados a Pub/Sub:

gcloud pubsub topics publish datos-topic \
  --message '{"id":"123","contenido":"Mensaje de prueba","timestamp":"2025-01-14T12:00:00Z"}'

messageIds:
- '13531497031954997'
---
### **2.4 Diagrama de Arquitectura:**
- https://drive.google.com/file/d/1XTSk-mBAVAPTKsSG6DKX_VgDACknp_h8/view?usp=sharing

#### Infraestructura Propuesta

1. **Ingesta de Datos (Google Cloud Pub/Sub)**

Componentes:
- T√≥pico (datos-topic): Recibe los datos enviados por los productores.
- Suscripci√≥n (datos-subscription): Entrega los mensajes a los consumidores.

Raz√≥n: Desacopla productores y consumidores, garantiza entrega de mensajes y escala autom√°ticamente.

2. **Almacenamiento de Datos (Google BigQuery)**

Componentes:
- Dataset (latam_dataset): Contiene la tabla datos.
- Tabla (datos): Almacena los datos con un esquema anal√≠tico optimizado.

Raz√≥n: BigQuery es ideal para consultas r√°pidas y escalables en grandes vol√∫menes de datos.

3. **Exposici√≥n de Datos (FastAPI en Google Cloud Run)**

Componentes:
- FastAPI: API con endpoints /health y /datos.
- Cloud Run: Despliega la API como un contenedor serverless.

Raz√≥n: Cloud Run escala autom√°ticamente seg√∫n la demanda, optimizando costos y garantizando disponibilidad.

4. **CI/CD con GitHub Actions**

Pipeline:
- Construcci√≥n y despliegue de contenedores Docker.
- Infraestructura gestionada con Terraform.
- Pruebas de integraci√≥n y carga autom√°ticas.

Raz√≥n: Automatizaci√≥n completa para garantizar calidad y despliegues consistentes.

**Resumen del Proceso**
Publicaci√≥n de Datos: Los datos ingresan a trav√©s de Pub/Sub.
Procesamiento: Se validan y almacenan en BigQuery.
Consumo: Los datos se exponen mediante una API HTTP desplegada en Cloud Run.
Automatizaci√≥n: CI/CD gestiona el flujo completo desde c√≥digo hasta producci√≥n.

---

## üß™ **Parte 3: Pruebas de Integraci√≥n y Puntos Cr√≠ticos de Calidad**

### **3.1 Implementar en el flujo CI/CD un test de integraci√≥n que verifique que la API efectivamente est√° exponiendo los datos de la base de datos. Argumentaci√≥n.**

- **Descripci√≥n**: Se incluy√≥ un test de integraci√≥n que valida si el endpoint `/datos` retorna datos almacenados en BigQuery.
- **Objetivo**: Garantizar que la API HTTP funcione correctamente y exponga los datos como se espera.
- **Implementaci√≥n**: Los tests se ejecutan autom√°ticamente en el pipeline CI/CD, aprovechando GitHub Actions.
- **C√≥digo de tests**: /latam-challenge/tests/integration/test_api.py
```python
  def test_health_endpoint():
    response = requests.get(f"{BASE_URL}/health")
    assert response.status_code == 200
    assert response.json() == {"status": "ok"}
    
def test_datos_endpoint():
    response = requests.get(f"{BASE_URL}/datos")
    assert response.status_code == 200
    assert "datos" in response.json()
```
- **Justificaci√≥n:**
Este test asegura que la conexi√≥n entre la API y BigQuery est√© configurada correctamente.
Adem√°s, se verifica la estructura y contenido de la respuesta de la API.

https://github.com/fernachbauer/latam-challenge/actions/runs/12771103343/job/35597552427
Run pytest tests/

============================= test session starts ==============================
platform linux -- Python 3.9.21, pytest-8.3.4, pluggy-1.5.0
rootdir: /home/runner/work/latam-challenge/latam-challenge
plugins: anyio-4.8.0
collected 2 items

tests/integration/test_api.py ..                                         [100%]

============================== 2 passed in 1.09s ===============================
---
### **3.2 Proponer otras pruebas de integraci√≥n que validen que el sistema est√° funcionando correctamente y c√≥mo se implementar√≠an**

* **Test de Ingesta de Datos:**

**Descripci√≥n:** Validar que los datos publicados en Pub/Sub se almacenen correctamente en BigQuery.

**Implementaci√≥n propuesta:**
- Simular la publicaci√≥n de un mensaje en el t√≥pico datos-topic.
- Confirmar que los datos aparezcan en la tabla datos de BigQuery.

* **Test de validaci√≥n de mensajes:**

**Descripci√≥n:** Verificar que los mensajes malformados enviados a Pub/Sub no se almacenen en BigQuery.

Implementaci√≥n propuesta:
- Enviar un mensaje con formato incorrecto al t√≥pico.
- Asegurar que no aparece en la tabla datos.

* **Test de Endpoint /health con Dependencias Externas:**

**Descripci√≥n:** Verificar que el endpoint /health no solo confirma la disponibilidad de la API, sino tambi√©n la conectividad con servicios externos como BigQuery.

**C√≥digo Ejemplo:**
```python
def test_health_with_dependencies():
    response = requests.get(f"{BASE_URL}/health")
    assert response.status_code == 200
    assert response.json() == {"status": "ok"}
    
    # Validar conectividad con BigQuery
    try:
        query = "SELECT 1"
        query_job = bigquery_client.query(query)
        assert query_job.result()
    except Exception as e:
        assert False, f"Error de conectividad con BigQuery: {e}"
```
---
### 3.3. ‚ö†Ô∏è Puntos Cr√≠ticos Identificados y Pruebas de Rendimiento

üìâ **Posibles Puntos Cr√≠ticos:**

1. **Latencia en consultas a BigQuery:**  
   - Bajo cargas elevadas, las consultas a BigQuery presentan tiempos de respuesta variables.  
   - **Pruebas de carga** revelaron que la latencia promedio lleg√≥ hasta **~600ms**, superando el umbral √≥ptimo.

2. **Errores de ingesta de datos por formatos inv√°lidos:**  
   - La ausencia de validaci√≥n previa de los datos provenientes de **Pub/Sub** podr√≠a derivar en errores al insertar registros en **BigQuery**.

3. **Sobrecarga de la API bajo alta demanda:**  
   - Las pruebas de carga mostraron que el endpoint `/datos` maneja correctamente m√∫ltiples solicitudes **GET**, pero:
     - El sistema registr√≥ un **11.98% de fallos** en intentos de inserci√≥n (**POST**) por falta de implementaci√≥n de dicho endpoint.  
     - La latencia aument√≥ progresivamente, alcanzando picos de hasta **6 segundos** bajo carga continua.  
     - La **saturaci√≥n** de recursos limit√≥ la capacidad de respuesta eficiente.

üìà **Pruebas de Carga Implementadas:**

Se utiliz√≥ **Locust** para evaluar el rendimiento del sistema:

https://github.com/fernachbauer/latam-challenge/actions/runs/12771103343/job/35597552427

- **Usuarios concurrentes:** 50  
- **Tasa de incremento:** 10 usuarios/segundo  
- **Duraci√≥n:** 2 minutos  

üìÑ **Resultados clave:**

- ‚úÖ **GET /datos:** Respondi√≥ exitosamente con una latencia promedio aceptable de **400ms**.  
- ‚ùå **POST /datos:** El 100% de los intentos fallaron con error **405** (**Method Not Allowed**), evidenciando la **ausencia de un endpoint de ingesta directa**.  
- üìâ **Latencia creciente:** Se detect√≥ un crecimiento sostenido en los tiempos de respuesta, alcanzando **hasta 6 segundos** en momentos cr√≠ticos.

üîç **Conclusiones:**

- La API soporta cargas moderadas para **lectura**, pero **no escala adecuadamente** bajo alta demanda sostenida.  
- La falta de un endpoint para inserci√≥n directa limita el flujo de ingesta eficiente.  
- La latencia creciente podr√≠a afectar la experiencia del usuario final y generar **timeouts** en sistemas integrados.

üí° **Acciones Correctivas:**

1. **Optimizar consultas a BigQuery:**  
   - Implementar **particiones** y **clustering** para mejorar el tiempo de respuesta.  

2. **Implementar validaci√≥n de datos en la ingesta:**  
   - Prevenir fallos de inserci√≥n mediante validaciones estrictas antes de enviar datos a BigQuery.

3. **Incorporar balanceo de carga y autoescalado:**  
   - Desplegar instancias adicionales de la API en **Cloud Run** bajo demanda.  
   - Configurar balanceo de carga para distribuir el tr√°fico eficientemente.  

4. **Agregar el endpoint POST /datos:**  
   - Permitir la ingesta directa de datos y evitar sobrecargar el flujo Pub/Sub.
---

## **3.4 Proponer c√≥mo robustecer t√©cnicamente el sistema para compensar o solucionar dichos puntos cr√≠ticos**

### **Optimizaci√≥n de Consultas en BigQuery:**

- Usar particiones y clustering para mejorar el rendimiento de las consultas.
- Limitar el n√∫mero de registros retornados.

### **Validaci√≥n de Mensajes en Pub/Sub:**

- Implementar l√≥gica de validaci√≥n en el suscriptor antes de insertar datos en BigQuery.
- Registrar errores en un sistema de monitoreo para su an√°lisis.

### **Autoescalado y Balanceo de Carga:**

- Configurar Cloud Run para escalar autom√°ticamente con base en las m√©tricas de latencia o CPU.
- Utilizar un balanceador de carga para distribuir el tr√°fico de manera eficiente.

### **Monitoreo y Alertas:**

- Usar Google Cloud Monitoring para rastrear m√©tricas clave como:
    * Latencia en BigQuery.
    * Errores en Pub/Sub.
    * Tiempo de respuesta de la API.
- Configurar alertas basadas en l√≠mites cr√≠ticos (p. ej., latencia > 1s).

---
## üìä **Parte 4: M√©tricas y Monitoreo**

### **4.1 Proponer 3 m√©tricas cr√≠ticas para entender la salud y rendimiento del sistema end-to-end**

1. **üöÄ Tasa de Ingesta de Mensajes en Pub/Sub (Messages Published Rate)**  
   - **Descripci√≥n:** N√∫mero de mensajes publicados por segundo/minuto en el t√≥pico `datos-topic`.  
   - **Objetivo:** Detectar cuellos de botella en la ingesta de datos.  

2. **‚è±Ô∏è Latencia de Respuesta de la API (API Response Latency)**  
   - **Descripci√≥n:** Tiempo promedio de respuesta del endpoint `/datos` y `/health`.  
   - **Objetivo:** Identificar degradaci√≥n en el rendimiento de la API bajo diferentes cargas.  

3. **‚ùå Tasa de Errores de Ingesta (Error Rate in Data Ingestion)**  
   - **Descripci√≥n:** Porcentaje de mensajes fallidos al ser insertados desde Pub/Sub a BigQuery.  
   - **Objetivo:** Detectar problemas en el procesamiento de datos y prevenir p√©rdida de informaci√≥n.  

---

### **4.2 Proponer una herramienta de visualizaci√≥n y describe textualmente qu√© m√©tricas mostrar√≠a**

**üîç Herramienta Propuesta:** *Google Cloud Monitoring (Stackdriver)*

**üìä M√©tricas a visualizar:**

- **Tasa de Ingesta de Mensajes (Pub/Sub):** Gr√°fica de l√≠neas que muestra la cantidad de mensajes procesados por segundo.  
- **Latencia de Respuesta de la API:** Panel con tiempos de respuesta promedio, m√°ximo y percentiles.  
- **Errores de BigQuery:** Conteo de errores de inserci√≥n de datos, diferenciando entre errores transitorios y cr√≠ticos.  
- **Uso de Recursos (CPU/RAM):** Estado de utilizaci√≥n de recursos de Cloud Run.  

**üìà ¬øC√≥mo ayuda esta informaci√≥n?**  
- **Rendimiento:** Detectar cuellos de botella y optimizar recursos.  
- **Estabilidad:** Identificar picos de latencia y prevenir fallos en la API.  
- **Disponibilidad:** Asegurar la ingesta continua de datos y reacci√≥n ante errores cr√≠ticos.  

---

## **4.3 Implementaci√≥n de la herramienta de monitoreo en la nube**

**üîß Pasos de Implementaci√≥n:**

1. **Activar Cloud Monitoring:**  
   - Configurar Google Cloud Monitoring para recolectar m√©tricas de Pub/Sub, Cloud Run y BigQuery.  

2. **Configurar Exportaci√≥n de Logs:**  
   - Exportar logs de errores y m√©tricas de Pub/Sub a Cloud Monitoring.  

3. **Crear Dashboards Personalizados:**  
   - Dise√±ar paneles interactivos con gr√°ficos de l√≠neas, indicadores y tablas.  

4. **Configurar Alertas Autom√°ticas:**  
   - Definir umbrales para alertas cr√≠ticas (e.g., latencia > 1s, error rate > 5%).  

---

## **4.4 Escalamiento de la soluci√≥n a 50 sistemas similares**

**üîÑ Cambios en la Visualizaci√≥n:**

- **Segmentaci√≥n por Proyecto/Sistema:** Agrupar m√©tricas por cada instancia del sistema.  
- **Dashboard Global:** Vista consolidada para todas las instancias, destacando los sistemas cr√≠ticos.  
- **M√©tricas Agregadas:**  
  - Tasa de ingesta global vs. individual.  
  - Latencia promedio global.  
  - Comparativa de errores entre sistemas.  

**üîì Nuevas M√©tricas Desbloqueadas:**  
- **Balanceo de carga entre sistemas.**  
- **Uso de red entre regiones.**  
- **Distribuci√≥n geogr√°fica de usuarios y tr√°fico.**  

---

## **4.5 Dificultades o limitaciones en observabilidad por problemas de escalabilidad**

**‚ö†Ô∏è Riesgos Potenciales:**

1. **Sobrecarga de Monitoreo:**  
   - Aumento en costos por almacenamiento de logs y m√©tricas.  
   - Saturaci√≥n de dashboards con exceso de datos.  

2. **Falsos Positivos en Alertas:**  
   - Umbrales mal configurados pueden generar alertas innecesarias.  

3. **Fragmentaci√≥n de Informaci√≥n:**  
   - Dificultad para correlacionar m√©tricas si no se estandariza la recolecci√≥n de datos.  

**üõ†Ô∏è Propuestas de Mitigaci√≥n:**  
- **Uso de m√©tricas agregadas:** Consolidar datos para obtener insights globales.  
- **Optimizar reglas de alertas:** Definir umbrales din√°micos ajustados al contexto.  
- **Automatizar escalamiento:** Implementar autoescalado basado en m√©tricas cr√≠ticas.



---

# üéâ **¬°Gracias por la Oportunidad!** üôå

Quiero expresar mi m√°s sincero agradecimiento por la oportunidad de participar en el **LATAM Airlines DevSecOps/SRE Challenge**. üåé‚úàÔ∏è

Muchas gracias por recibir mi desaf√≠o, en el van muchas horas de esfuerzo y motivaci√≥n por la oportunidad de formar parte del equipo.

Este proyecto ha sido una experiencia incre√≠ble, en la que he invertido muchas horas llenas de **motivaci√≥n**, **aprendizaje** e **ilusi√≥n**. Cada l√≠nea de c√≥digo, cada despliegue y cada prueba fueron pensados con el compromiso de entregar una soluci√≥n robusta ,a la altura del desaf√≠o y la compa√±ia. üíª ‚úàÔ∏è‚úàÔ∏è‚úàÔ∏è‚úàÔ∏è‚úàÔ∏è‚úàÔ∏è

¬°Estoy emocionado por todo lo aprendido y por seguir creciendo en el mundo de la tecnolog√≠a! üåê

---

## üîß‚ú®‚úàÔ∏è **¬°Nos vemos en las nubes!** ‚òÅÔ∏è
           |
                       --====|====--
                             |  

                         .-"""""-. 
                       .'_________'. 
                      /_/_|__|__|_\_\
                     ;'-._       _.-';
,--------------------|    `-. .-'    |--------------------,
 ``""--..__    ___   ;       '       ;   ___    __..--""``
  jgs      `"-// \\.._\             /_..// \\-"`
              \\_//    '._       _.'    \\_//
               `"`        ``---``        `"`

üìÇ Repositorio
üîó https://github.com/fernachbauer/latam-challenge

üìß Contacto
Nombre: Fernando Nachbauer R
Correo: fernachbauer@gmail.com