

# üöÄ LATAM Airlines DevSecOps/SRE Challenge

## ‚ú® Descripci√≥n del Proyecto
Este proyecto implementa un sistema en la nube para ingestar, almacenar y exponer datos a trav√©s de una API HTTP para que puedan ser consumidos por terceros, utilizando infraestructura como c√≥digo (IaC) con Terraform y flujos de CI/CD con GitHub Actions. Adem√°s, se incorporaron pruebas de integraci√≥n, carga, monitoreo y propuestas de alertas para garantizar la resiliencia y escalabilidad del sistema.

---

## üèóÔ∏è Parte 1: Infraestructura e IaC

### **1. Identificar la infraestructura necesaria para ingestar, almacenar y exponer datos**

#### **1.1 Ingesta, almacenamiento y exposici√≥n de datos**

##### **1.1.a Utilizar el esquema Pub/Sub para ingesta de datos**
El sistema implementa un esquema de mensajer√≠a as√≠ncrona utilizando **Google Cloud Pub/Sub** para garantizar la ingesta eficiente de datos. La arquitectura incluye:

- **T√≥pico:** `datos-topic`
  - Este t√≥pico recibe los mensajes publicados por el sistema o usuarios externos.
  - Ejemplo de mensaje publicado:
    ```json
    {
      "id": "123",
      "contenido": "Este es un mensaje de prueba",
      "timestamp": "2025-01-14T10:00:00Z"
    }
    ```

- **Suscripci√≥n:** `datos-subscription`
  - Procesa los mensajes del t√≥pico y env√≠a los datos para su almacenamiento en BigQuery.

**Ventajas del esquema Pub/Sub:**
- Desacopla la producci√≥n y el consumo de datos, lo que facilita la escalabilidad.
- Proporciona resiliencia ante fallos temporales.
- Admite altos vol√∫menes de datos de manera eficiente.

##### **1.1.b Base de datos para el almacenamiento enfocado en anal√≠tica de datos**
Se utiliza **Google BigQuery** como base de datos principal para almacenar los datos. 

- **Dataset:** `latam_dataset`
- **Tabla:** `datos`
  - Esquema definido:
    ```json
    [
      {
        "name": "id",
        "type": "STRING",
        "mode": "REQUIRED",
        "description": "Identificador √∫nico del dato"
      },
      {
        "name": "contenido",
        "type": "STRING",
        "mode": "NULLABLE",
        "description": "Contenido del dato"
      },
      {
        "name": "timestamp",
        "type": "TIMESTAMP",
        "mode": "REQUIRED",
        "description": "Marca de tiempo del registro"
      }
    ]
    ```

**Beneficios de BigQuery:**
- Es ideal para tareas anal√≠ticas debido a su alta velocidad de consulta.
- Escalabilidad autom√°tica para grandes vol√∫menes de datos.
- F√°cil integraci√≥n con otros servicios de GCP.

##### **1.1.c Endpoint HTTP para servir parte de los datos almacenados**
Se implement√≥ una API utilizando **FastAPI** desplegada en **Google Cloud Run**. Esta API expone los datos almacenados en BigQuery y ofrece dos endpoints principales:

- **Endpoint `/health`:** 
  - Devuelve el estado del sistema.
  - Ejemplo de respuesta:
    ```json
    {
      "status": "ok"
    }
    ```

- **Endpoint `/datos`:**
  - Devuelve los √∫ltimos 10 registros almacenados en BigQuery.
  - Ejemplo de respuesta:
    ```json
    {
      "datos": [
        {
          "id": "789",
          "contenido": "Prueba autom√°tica",
          "timestamp": "2024-01-14T14:00:00+00:00"
        }
      ]
    }
    ```

---

#### **1.2 Deployar infraestructura mediante Terraform**

Se utiliz√≥ **Terraform** para automatizar la creaci√≥n y gesti√≥n de la infraestructura en Google Cloud Platform. Los recursos desplegados incluyen:

- **Google Cloud Pub/Sub:**
  - T√≥pico: `datos-topic`
  - Suscripci√≥n: `datos-subscription`

- **Google BigQuery:**
  - Dataset: `latam_dataset`
  - Tabla: `datos`

- **Google Cloud Run:**
  - API desplegada para exposici√≥n de datos.

---
## üîÑ Parte 2: Aplicaciones y flujo CI/CD

### **2.1 API HTTP**

La API HTTP fue desarrollada utilizando **FastAPI** para garantizar un alto rendimiento y facilidad de implementaci√≥n. Los endpoints principales permiten la exposici√≥n de datos almacenados en la base de datos.

#### **Endpoints implementados:**
- **GET `/health`:** 
  - Verifica la salud de la API y confirma que est√° operativa.
  - **Respuesta de ejemplo:**
    ```json
    {
      "status": "ok"
    }
    ```

- **GET `/datos`:**
  - Recupera los √∫ltimos registros almacenados en **Google BigQuery**.
  - **Respuesta de ejemplo:**
    ```json
    {
      "datos": [
        {
          "id": "789",
          "contenido": "Prueba autom√°tica",
          "timestamp": "2024-01-14T14:00:00+00:00"
        }
      ]
    }
    ```

**L√≥gica implementada:**
- Conexi√≥n directa con **Google BigQuery** utilizando su cliente oficial de Python.
- Queries optimizadas para limitar los resultados y garantizar baja latencia.

---

### **2.2 Deployar API HTTP mediante CI/CD**

El despliegue de la API HTTP se realiza utilizando un flujo de **CI/CD con GitHub Actions**. Este pipeline automatiza los pasos de construcci√≥n, prueba y despliegue en **Google Cloud Run**.

#### **2.2.1 Flujo del pipeline CI/CD:**
1. **Build Docker Image:**
   - Construcci√≥n de la imagen Docker de la API.
   - Push de la imagen a **Google Container Registry (GCR)**.

2. **Deploy con Terraform:**
   - Terraform aplica los cambios para actualizar la infraestructura, incluyendo el despliegue de la API en **Google Cloud Run**.

3. **Pruebas Autom√°ticas:**
   - Pruebas de integraci√≥n y carga para validar los endpoints `/health` y `/datos`.

##### **Archivo GitHub Actions (`.github/workflows/deploy.yml`):**


### üì¶ Evidencias
- Pipeline exitoso: Logs de GitHub Actions.
https://github.com/fernachbauer/latam-challenge/actions/runs/12771103343

---
### **2.3 (Opcional) Ingesta de datos desde Pub/Sub**

En esta etapa opcional, se implement√≥ una l√≥gica para procesar los mensajes recibidos en **Google Cloud Pub/Sub** y almacenarlos en la base de datos **Google BigQuery**.

#### **Objetivo:**
- Configurar una suscripci√≥n a **Pub/Sub** que permita:
  1. Recibir mensajes publicados en el t√≥pico `datos-topic`.
  2. Procesar y validar los datos.
  3. Almacenar los datos recibidos en la tabla `datos` del dataset `latam_dataset` en **BigQuery**.


#### **Flujo del procesamiento:**

1. **Publicaci√≥n de datos:**
   - Los datos son enviados al t√≥pico `datos-topic` mediante el cliente de **Pub/Sub**.

2. **Procesamiento de mensajes:**
   - Se configura la suscripci√≥n `datos-subscription` para recibir los mensajes del t√≥pico.
   - Los mensajes son procesados a trav√©s de un **callback** que:
     - Decodifica y valida los datos.
     - Inserta los registros en la tabla de **BigQuery**.

3. **Inserci√≥n en BigQuery:**
   - Los datos se insertan en la tabla `datos`, aprovechando las capacidades de la API de BigQuery.

#### Ventajas de esta implementaci√≥n:
- **Escalabilidad:** Pub/Sub maneja un alto volumen de mensajes.
- **Flexibilidad:** Los datos malformados pueden ser gestionados en el callback.
- **Integraci√≥n serverless:** La combinaci√≥n de Pub/Sub y BigQuery simplifica la operaci√≥n.

#### **Evidencias:**
Mensajes enviados a Pub/Sub:

gcloud pubsub topics publish datos-topic \
  --message '{"id":"123","contenido":"Mensaje de prueba","timestamp":"2025-01-14T12:00:00Z"}'

messageIds:
- '13531497031954997'
---
### **2.4 Diagrama de Arquitectura:**
- https://drive.google.com/file/d/1XTSk-mBAVAPTKsSG6DKX_VgDACknp_h8/view?usp=sharing

<div align="center">
    <img src="./arquitectura-api-latam.png" alt="Arquitectura de la Soluci√≥n" width="800"/>
</div>


#### Infraestructura Propuesta

1. **Ingesta de Datos (Google Cloud Pub/Sub)**

Componentes:
- T√≥pico (datos-topic): Recibe los datos enviados por los productores.
- Suscripci√≥n (datos-subscription): Entrega los mensajes a los consumidores.

Raz√≥n: Desacopla productores y consumidores, garantiza entrega de mensajes y escala autom√°ticamente.

2. **Almacenamiento de Datos (Google BigQuery)**

Componentes:
- Dataset (latam_dataset): Contiene la tabla datos.
- Tabla (datos): Almacena los datos con un esquema anal√≠tico optimizado.

Raz√≥n: BigQuery es ideal para consultas r√°pidas y escalables en grandes vol√∫menes de datos.

3. **Exposici√≥n de Datos (FastAPI en Google Cloud Run)**

Componentes:
- FastAPI: API con endpoints /health y /datos.
- Cloud Run: Despliega la API como un contenedor serverless.

Raz√≥n: Cloud Run escala autom√°ticamente seg√∫n la demanda, optimizando costos y garantizando disponibilidad.

4. **CI/CD con GitHub Actions**

Pipeline:
- Construcci√≥n y despliegue de contenedores Docker.
- Infraestructura gestionada con Terraform.
- Pruebas de integraci√≥n y carga autom√°ticas.

Raz√≥n: Automatizaci√≥n completa para garantizar calidad y despliegues consistentes.

**Resumen del Proceso**
Publicaci√≥n de Datos: Los datos ingresan a trav√©s de Pub/Sub.
Procesamiento: Se validan y almacenan en BigQuery.
Consumo: Los datos se exponen mediante una API HTTP desplegada en Cloud Run.
Automatizaci√≥n: CI/CD gestiona el flujo completo desde c√≥digo hasta producci√≥n.

---

## üß™ **Parte 3: Pruebas de Integraci√≥n y Puntos Cr√≠ticos de Calidad**

### **3.1 Implementar en el flujo CI/CD un test de integraci√≥n que verifique que la API efectivamente est√° exponiendo los datos de la base de datos. Argumentaci√≥n.**

- **Descripci√≥n**: Se incluy√≥ un test de integraci√≥n que valida si el endpoint `/datos` retorna datos almacenados en BigQuery.
- **Objetivo**: Garantizar que la API HTTP funcione correctamente y exponga los datos como se espera.
- **Implementaci√≥n**: Los tests se ejecutan autom√°ticamente en el pipeline CI/CD, aprovechando GitHub Actions.
- **C√≥digo de tests**: /latam-challenge/tests/integration/test_api.py
```python
  def test_health_endpoint():
    response = requests.get(f"{BASE_URL}/health")
    assert response.status_code == 200
    assert response.json() == {"status": "ok"}
    
def test_datos_endpoint():
    response = requests.get(f"{BASE_URL}/datos")
    assert response.status_code == 200
    assert "datos" in response.json()
```
- **Justificaci√≥n:**
Este test asegura que la conexi√≥n entre la API y BigQuery est√© configurada correctamente.
Adem√°s, se verifica la estructura y contenido de la respuesta de la API.

https://github.com/fernachbauer/latam-challenge/actions/runs/12771103343/job/35597552427
Run pytest tests/

============================= test session starts ==============================
platform linux -- Python 3.9.21, pytest-8.3.4, pluggy-1.5.0
rootdir: /home/runner/work/latam-challenge/latam-challenge
plugins: anyio-4.8.0
collected 2 items

tests/integration/test_api.py ..                                         [100%]

============================== 2 passed in 1.09s ===============================
---
### **3.2 Proponer otras pruebas de integraci√≥n que validen que el sistema est√° funcionando correctamente y c√≥mo se implementar√≠an**

* **Test de Ingesta de Datos:**

**Descripci√≥n:** Validar que los datos publicados en Pub/Sub se almacenen correctamente en BigQuery.

**Implementaci√≥n propuesta:**
- Simular la publicaci√≥n de un mensaje en el t√≥pico datos-topic.
- Confirmar que los datos aparezcan en la tabla datos de BigQuery.

* **Test de validaci√≥n de mensajes:**

**Descripci√≥n:** Verificar que los mensajes malformados enviados a Pub/Sub no se almacenen en BigQuery.

Implementaci√≥n propuesta:
- Enviar un mensaje con formato incorrecto al t√≥pico.
- Asegurar que no aparece en la tabla datos.

* **Test de Endpoint /health con Dependencias Externas:**

**Descripci√≥n:** Verificar que el endpoint /health no solo confirma la disponibilidad de la API, sino tambi√©n la conectividad con servicios externos como BigQuery.

**C√≥digo Ejemplo:**
```python
def test_health_with_dependencies():
    response = requests.get(f"{BASE_URL}/health")
    assert response.status_code == 200
    assert response.json() == {"status": "ok"}
    
    # Validar conectividad con BigQuery
    try:
        query = "SELECT 1"
        query_job = bigquery_client.query(query)
        assert query_job.result()
    except Exception as e:
        assert False, f"Error de conectividad con BigQuery: {e}"
```
---
### 3.3. ‚ö†Ô∏è Puntos Cr√≠ticos Identificados y Pruebas de Rendimiento

üìâ **Posibles Puntos Cr√≠ticos:**

1. **Latencia en consultas a BigQuery:**  
   - Bajo cargas elevadas, las consultas a BigQuery presentan tiempos de respuesta variables.  
   - **Pruebas de carga** revelaron que la latencia promedio lleg√≥ hasta **~600ms**, superando el umbral √≥ptimo.

2. **Errores de ingesta de datos por formatos inv√°lidos:**  
   - La ausencia de validaci√≥n previa de los datos provenientes de **Pub/Sub** podr√≠a derivar en errores al insertar registros en **BigQuery**.

3. **Sobrecarga de la API bajo alta demanda:**  
   - Las pruebas de carga mostraron que el endpoint `/datos` maneja correctamente m√∫ltiples solicitudes **GET**, pero:
     - El sistema registr√≥ un **11.98% de fallos** en intentos de inserci√≥n (**POST**) por falta de implementaci√≥n de dicho endpoint.  
     - La latencia aument√≥ progresivamente, alcanzando picos de hasta **6 segundos** bajo carga continua.  
     - La **saturaci√≥n** de recursos limit√≥ la capacidad de respuesta eficiente.

üìà **Pruebas de Carga Implementadas:**

Se utiliz√≥ **Locust** para evaluar el rendimiento del sistema:

https://github.com/fernachbauer/latam-challenge/actions/runs/12771103343/job/35597552427

- **Usuarios concurrentes:** 50  
- **Tasa de incremento:** 10 usuarios/segundo  
- **Duraci√≥n:** 2 minutos  

üìÑ **Resultados clave:**

- ‚úÖ **GET /datos:** Respondi√≥ exitosamente con una latencia promedio aceptable de **400ms**.  
- ‚ùå **POST /datos:** El 100% de los intentos fallaron con error **405** (**Method Not Allowed**), evidenciando la **ausencia de un endpoint de ingesta directa**.  
- üìâ **Latencia creciente:** Se detect√≥ un crecimiento sostenido en los tiempos de respuesta, alcanzando **hasta 6 segundos** en momentos cr√≠ticos.

üîç **Conclusiones:**

- La API soporta cargas moderadas para **lectura**, pero **no escala adecuadamente** bajo alta demanda sostenida.  
- La falta de un endpoint para inserci√≥n directa limita el flujo de ingesta eficiente.  
- La latencia creciente podr√≠a afectar la experiencia del usuario final y generar **timeouts** en sistemas integrados.

üí° **Acciones Correctivas:**

1. **Optimizar consultas a BigQuery:**  
   - Implementar **particiones** y **clustering** para mejorar el tiempo de respuesta.  

2. **Implementar validaci√≥n de datos en la ingesta:**  
   - Prevenir fallos de inserci√≥n mediante validaciones estrictas antes de enviar datos a BigQuery.

3. **Incorporar balanceo de carga y autoescalado:**  
   - Desplegar instancias adicionales de la API en **Cloud Run** bajo demanda.  
   - Configurar balanceo de carga para distribuir el tr√°fico eficientemente.  

4. **Agregar el endpoint POST /datos:**  
   - Permitir la ingesta directa de datos y evitar sobrecargar el flujo Pub/Sub.
---

## **3.4 Proponer c√≥mo robustecer t√©cnicamente el sistema para compensar o solucionar dichos puntos cr√≠ticos**

### **Optimizaci√≥n de Consultas en BigQuery:**

- Usar particiones y clustering para mejorar el rendimiento de las consultas.
- Limitar el n√∫mero de registros retornados.

### **Validaci√≥n de Mensajes en Pub/Sub:**

- Implementar l√≥gica de validaci√≥n en el suscriptor antes de insertar datos en BigQuery.
- Registrar errores en un sistema de monitoreo para su an√°lisis.

### **Autoescalado y Balanceo de Carga:**

- Configurar Cloud Run para escalar autom√°ticamente con base en las m√©tricas de latencia o CPU.
- Utilizar un balanceador de carga para distribuir el tr√°fico de manera eficiente.

### **Monitoreo y Alertas:**

- Usar Google Cloud Monitoring para rastrear m√©tricas clave como:
    * Latencia en BigQuery.
    * Errores en Pub/Sub.
    * Tiempo de respuesta de la API.
- Configurar alertas basadas en l√≠mites cr√≠ticos (p. ej., latencia > 1s).

---
## üìä **Parte 4: M√©tricas y Monitoreo**

### **4.1 Proponer 3 m√©tricas cr√≠ticas para entender la salud y rendimiento del sistema end-to-end**

1. **üöÄ Tasa de Ingesta de Mensajes en Pub/Sub (Messages Published Rate)**  
   - **Descripci√≥n:** N√∫mero de mensajes publicados por segundo/minuto en el t√≥pico `datos-topic`.  
   - **Objetivo:** Detectar cuellos de botella en la ingesta de datos.  

2. **‚è±Ô∏è Latencia de Respuesta de la API (API Response Latency)**  
   - **Descripci√≥n:** Tiempo promedio de respuesta del endpoint `/datos` y `/health`.  
   - **Objetivo:** Identificar degradaci√≥n en el rendimiento de la API bajo diferentes cargas.  

3. **‚ùå Tasa de Errores de Ingesta (Error Rate in Data Ingestion)**  
   - **Descripci√≥n:** Porcentaje de mensajes fallidos al ser insertados desde Pub/Sub a BigQuery.  
   - **Objetivo:** Detectar problemas en el procesamiento de datos y prevenir p√©rdida de informaci√≥n.  

---

### **4.2 Proponer una herramienta de visualizaci√≥n y describe textualmente qu√© m√©tricas mostrar√≠a**

**üîç Herramienta Propuesta:** *Google Cloud Monitoring (Stackdriver)*

**üìä M√©tricas a visualizar:**

- **Tasa de Ingesta de Mensajes (Pub/Sub):** Gr√°fica de l√≠neas que muestra la cantidad de mensajes procesados por segundo.  
- **Latencia de Respuesta de la API:** Panel con tiempos de respuesta promedio, m√°ximo y percentiles.  
- **Errores de BigQuery:** Conteo de errores de inserci√≥n de datos, diferenciando entre errores transitorios y cr√≠ticos.  
- **Uso de Recursos (CPU/RAM):** Estado de utilizaci√≥n de recursos de Cloud Run.  

**üìà ¬øC√≥mo ayuda esta informaci√≥n?**  
- **Rendimiento:** Detectar cuellos de botella y optimizar recursos.  
- **Estabilidad:** Identificar picos de latencia y prevenir fallos en la API.  
- **Disponibilidad:** Asegurar la ingesta continua de datos y reacci√≥n ante errores cr√≠ticos.  

---

## **4.3 Implementaci√≥n de la herramienta de monitoreo en la nube**

**üîß Pasos de Implementaci√≥n:**

1. **Activar Cloud Monitoring:**  
   - Configurar Google Cloud Monitoring para recolectar m√©tricas de Pub/Sub, Cloud Run y BigQuery.  

2. **Configurar Exportaci√≥n de Logs:**  
   - Exportar logs de errores y m√©tricas de Pub/Sub a Cloud Monitoring.  

3. **Crear Dashboards Personalizados:**  
   - Dise√±ar paneles interactivos con gr√°ficos de l√≠neas, indicadores y tablas.  

4. **Configurar Alertas Autom√°ticas:**  
   - Definir umbrales para alertas cr√≠ticas (e.g., latencia > 1s, error rate > 5%).  

---

## **4.4 Escalamiento de la soluci√≥n a 50 sistemas similares**

**üîÑ Cambios en la Visualizaci√≥n:**

Se debe tener una mirada mas general de los sistemas, abordando KPI agrupados y m√©tricas que permitan gestionar mayor vol√∫men de instancias o aplicaciones con menor esfuerzo. Para ello, hay que alinear las necesidades t√©cnicas de la continuidad operacional con la vista estrat√©gica de la compa√±ia, prioridades de ingesta para procesos cr√≠ticos, calendario de jobs, se deben clasificar los tipos de procesos operacionales a lo largo de todo el ciclo de vida de los datos.

Dado esto se hace necesario crear un paneles t√°cticos y estrat√©gicos para poder despejar la informaci√≥n y agruparla en sinton√≠a con las decisiones que se deben tomar a nivel de recursos en la nube y el presupuesto asignado para los distintos recursos cloud.

Entonces, para administrar **50 sistemas similares** que exponen APIs y manejan flujos de datos cr√≠ticos, es esencial construir **paneles de monitoreo** eficientes que permitan supervisar tanto la **operaci√≥n t√©cnica** como la **estrategia de negocio**. Esto implica usar visualizaciones e indicadores espec√≠ficos que faciliten la toma de decisiones. Aqu√≠ te propongo una estructura de paneles con m√©tricas e indicadores clave:

Es por ello que se proponen algunas formas de segmentar recursos:

- **Segmentaci√≥n por Proyecto/Sistema:** Agrupar m√©tricas por cada instancia del sistema.  
- **Dashboard Global:** Vista consolidada para todas las instancias, destacando los sistemas cr√≠ticos.  
- **M√©tricas Agregadas:**  
  - Tasa de ingesta global vs. individual. (Fallos, Incidenciasm etc)  
  - Latencia promedio global.  
  - Comparativa de errores entre sistemas.
  - Agrupaciones customizadas que aporten informaci√≥n estrat√©gica para un KPI de la compa√±ia. 

**üîì Nuevas M√©tricas Desbloqueadas:**

## üìä **Panel Estrat√©gico de Alto Nivel (Executive Dashboard)**

**Objetivo:** Proveer una visi√≥n global y simplificada del estado de los sistemas, alineada con los objetivos estrat√©gicos de la empresa.

### üîë **Indicadores Clave (KPIs):**

- **Disponibilidad General (%):** Uptime consolidado de todos los sistemas.  
- **Tiempo Promedio de Respuesta (ms):** Latencia media de todas las APIs.  
- **Errores Cr√≠ticos (5xx) Globales:** N√∫mero de fallas cr√≠ticas por entorno.  
- **Uso de Recursos por Sistema:** CPU, memoria y almacenamiento usados.  
- **Costo de Operaci√≥n ($):** Gasto mensual por servicio (APIs, Pub/Sub, BigQuery).  
- **Prioridad de Procesos Cr√≠ticos:** Estado de los sistemas clasificados por prioridad.

### üìä **Visualizaciones:**

- **Heatmaps:** Mapas de calor para ver disponibilidad por regi√≥n o servicio.  
- **Gr√°ficos de L√≠neas:** Evoluci√≥n del uso de recursos (CPU/RAM) en el tiempo.  
- **Gr√°ficos de Barras:** Comparaci√≥n de costos operativos por sistema.  
- **Sem√°foros de Estado:** Indicadores visuales (verde, amarillo, rojo) para servicios cr√≠ticos.

---

## ‚öôÔ∏è **Panel T√©cnico Operacional (Ops Dashboard)**

**Objetivo:** Supervisar el rendimiento y la salud operativa de cada API y su infraestructura.

### üîë **Indicadores Clave (KPIs):**

- **Latencia por API:** Tiempo de respuesta segregado por endpoint.  
- **Errores 4xx/5xx:** Tasa de errores de cliente y servidor.  
- **Tasa de √âxito de Ingesta (Pub/Sub):** % de mensajes procesados correctamente.  
- **Backlogs de Pub/Sub:** Mensajes pendientes de procesar por suscripci√≥n.  
- **Uso de BigQuery:** Consultas por segundo y tiempos de ejecuci√≥n.

### üìä **Visualizaciones:**

- **Gr√°ficos de L√≠neas por Servicio:** Latencia, errores y tr√°fico por API.  
- **Histograma de Latencia:** Distribuci√≥n de tiempos de respuesta.  
- **Panel de M√©tricas de Pub/Sub:** Publicaci√≥n y procesamiento de mensajes.  
- **Alertas en Tiempo Real:** Panel con logs y alertas activas.

---

## üöÄ **Panel de Escalabilidad y Costos (Scaling & Cost Dashboard)**

**Objetivo:** Optimizar el uso de recursos y controlar costos ante el crecimiento de los sistemas.

### üîë **Indicadores Clave (KPIs):**

- **Uso de Autoescalado:** Niveles de escalamiento de Cloud Run.  
- **Costo por API:** Desglose de costos de operaci√≥n por servicio.  
- **Costo por Regi√≥n/Entorno:** Gastos seg√∫n ubicaci√≥n geogr√°fica.  
- **Capacidad Reservada vs. Uso Real:** Eficiencia de recursos.

### üìä **Visualizaciones:**

- **Stacked Bar Charts:** Costos por componente (API, almacenamiento, red).  
- **Heatmap de Uso de Recursos:** Uso de CPU y memoria en Cloud Run.  
- **Gr√°ficos de L√≠neas:** Tendencia de costos vs. tr√°fico de usuarios.

---

## üõ°Ô∏è **Panel de Seguridad y Cumplimiento (Security Dashboard)**

**Objetivo:** Garantizar la seguridad de los sistemas y el cumplimiento normativo.

### üîë **Indicadores Clave (KPIs):**

- **Intentos de Acceso Fallidos:** N√∫mero de intentos de acceso no autorizados.  
- **Errores de Autenticaci√≥n:** Fallos de autenticaci√≥n de usuarios/API Keys.  
- **Permisos y Roles Inadecuados:** Cambios inusuales en roles de IAM.  
- **Eventos de Seguridad:** Logs de incidentes de seguridad.

### üìä **Visualizaciones:**

- **Tablas de Auditor√≠a:** Accesos por usuario/servicio.  
- **Gr√°ficos de Radar:** Comparativa de riesgos por sistema.  
- **Timeline de Incidentes:** Cronolog√≠a de eventos de seguridad.

---

## üõ†Ô∏è **Herramientas para Implementar los Dashboards**

- **Google Cloud Monitoring (Stackdriver):** Para monitorear servicios de Google Cloud.  
- **Grafana:** Visualizaci√≥n avanzada de m√©tricas t√©cnicas.  
- **BigQuery + Looker Studio:** An√°lisis de grandes vol√∫menes de datos.  
- **Prometheus:** Recolecci√≥n de m√©tricas a nivel de infraestructura.  
- **PagerDuty / Opsgenie:** Gesti√≥n de alertas y respuesta a incidentes.

---

## üìà **M√©tricas Avanzadas para Escalamiento**

- **Tasa de Peticiones Concurrentes:** Relaci√≥n entre tr√°fico entrante y capacidad de respuesta.  
- **Colas de Mensajes (Pub/Sub):** Detecci√≥n de cuellos de botella en la ingesta.  
- **Tasa de Fallos Transitorios:** Errores intermitentes que podr√≠an ser mitigados con reintentos.  
- **Elasticidad de Autoescalado:** Capacidad del sistema de escalar de forma eficiente.  
- **Costo Eficiencia:** Costo por transacci√≥n o por volumen de datos procesado.

---

## üîë **Conclusi√≥n**

Para escalar a **50 sistemas similares**, es fundamental implementar dashboards claros y jerarquizados, donde se visualicen m√©tricas estrat√©gicas, operacionales, de costos y de seguridad. Estos paneles permitir√°n tomar decisiones informadas, optimizar recursos y garantizar la **resiliencia** y **escalabilidad** del sistema.

---

## **4.5 Dificultades o limitaciones en observabilidad por problemas de escalabilidad**

**‚ö†Ô∏è Riesgos Potenciales:**

1. **Sobrecarga de Monitoreo:**  
   - Aumento en costos por almacenamiento de logs y m√©tricas.  
   - Saturaci√≥n de dashboards con exceso de datos.  

2. **Falsos Positivos en Alertas:**  
   - Umbrales mal configurados pueden generar alertas innecesarias.  

3. **Fragmentaci√≥n de Informaci√≥n:**  
   - Dificultad para correlacionar m√©tricas si no se estandariza la recolecci√≥n de datos.  

**üõ†Ô∏è Propuestas de Mitigaci√≥n:**  
- **Uso de m√©tricas agregadas:** Consolidar datos para obtener insights globales.  
- **Optimizar reglas de alertas:** Definir umbrales din√°micos ajustados al contexto.  
- **Automatizar escalamiento:** Implementar autoescalado basado en m√©tricas cr√≠ticas.

---

# ‚ö†Ô∏è Parte 5: Alertas y SRE (Opcional)

## 5.1 üîî **Definici√≥n de Reglas y Umbrales de Alerta**

Las siguientes reglas de alerta est√°n dise√±adas para anticipar problemas cr√≠ticos en el sistema y mantener su rendimiento √≥ptimo.

### üö® **Alertas Cr√≠ticas**

| **M√©trica**                                  | **Umbral Cr√≠tico**                             | **Impacto**                                            | **Acci√≥n Correctiva**                                   |
|----------------------------------------------|------------------------------------------------|-------------------------------------------------------|--------------------------------------------------------|
| **Disponibilidad de la API HTTP**            | < 99.9% de uptime mensual                      | P√©rdida de disponibilidad del servicio.                | Escalar al equipo de infraestructura.                   |
| **Latencia de Respuesta de la API**          | > 500ms sostenido por m√°s de 5 minutos         | Degradaci√≥n de la experiencia del usuario.             | Activar autoescalado en Cloud Run.                     |
| **Errores 5xx en la API HTTP**              | > 2% del total de peticiones en 10 minutos     | Fallos en la infraestructura o backend.               | Inspeccionar logs y aplicar rollback si es necesario.  |
| **Tasa de Mensajes No Procesados (Pub/Sub)** | > 5% durante 15 minutos                        | Riesgo de p√©rdida o retraso de datos.                 | Incrementar capacidad de procesamiento.                |
| **Uso de CPU/Memoria**                      | CPU > 85% o RAM > 80% por m√°s de 10 minutos    | Saturaci√≥n de instancias y posible ca√≠da del servicio.| Revisar autoescalado y optimizar recursos.             |

### ‚ö†Ô∏è **Alertas Moderadas**

| **M√©trica**                                | **Umbral**                              | **Impacto**                                 | **Acci√≥n Correctiva**                           |
|--------------------------------------------|----------------------------------------|--------------------------------------------|------------------------------------------------|
| **Errores 4xx en API HTTP**                | > 10% del total de peticiones           | Problemas con solicitudes incorrectas.     | Revisar uso de la API y mejorar documentaci√≥n. |
| **Costos de Operaci√≥n**                    | > 20% del presupuesto mensual proyectado | Riesgo financiero por sobrecostos.         | Revisar configuraciones y recursos asignados.  |
| **Backlog en Pub/Sub**                     | Crecimiento constante sin estabilizarse | Cuello de botella en la ingesta de datos.  | Aumentar paralelismo en la suscripci√≥n.        |

---

## 5.2 üìè **Definici√≥n de SLIs/SLOs**

### üîç **SLIs (Service Level Indicators)**

| **SLI**                                     | **Descripci√≥n**                                          | **Umbral Cr√≠tico**                       | **Herramienta de Monitoreo**                  |
|---------------------------------------------|----------------------------------------------------------|-----------------------------------------|----------------------------------------------|
| **Disponibilidad de la API HTTP**           | % de tiempo que la API responde correctamente (2xx).     | < 99.9% mensual                         | Google Cloud Monitoring (Stackdriver).       |
| **Latencia de Respuesta de la API HTTP**    | Tiempo promedio de respuesta.                            | > 500ms sostenido por 5 minutos.        | Stackdriver, m√©tricas de Cloud Run.         |
| **Tasa de Error (Error Rate)**              | % de respuestas 5xx sobre el total de peticiones.        | > 2% sostenido en 10 minutos.          | Logs y m√©tricas de Cloud Run.              |
| **Procesamiento en Pub/Sub**                | % de mensajes procesados exitosamente.                   | < 95% de procesamiento en 15 minutos.  | M√©tricas de Pub/Sub.                      |

### üéØ **SLOs (Service Level Objectives)**

| **SLO**                                     | **Objetivo**                                   | **Justificaci√≥n**                                  |
|---------------------------------------------|------------------------------------------------|----------------------------------------------------|
| **Disponibilidad de la API HTTP**           | ‚â• 99.9% mensual                                | Minimizar interrupciones y asegurar continuidad.   |
| **Latencia de Respuesta**                   | ‚â§ 500ms en el 95% de las peticiones.           | Garantizar experiencia de usuario fluida.          |
| **Tasa de Error**                           | ‚â§ 1% de errores 5xx por semana.               | Mantener confiabilidad y disponibilidad.           |
| **Procesamiento en Pub/Sub**                | ‚â• 98% de mensajes procesados sin error.        | Asegurar flujo continuo de ingesta de datos.       |

---

## üí° **Razonamiento de Selecci√≥n de SLIs/SLOs**

| **Raz√≥n de Selecci√≥n**                   | **M√©tricas Incluidas**                                  | **M√©tricas Excluidas**                             |
|-----------------------------------------|--------------------------------------------------------|---------------------------------------------------|
| **Impacto directo en el usuario**       | Disponibilidad, Latencia, Errores 5xx.                 | Uso de disco y m√©tricas internas no visibles.     |
| **Continuidad del negocio**             | Tasa de procesamiento en Pub/Sub.                      | M√©tricas de tr√°fico interno.                      |
| **Balance entre rigor y flexibilidad**  | Umbrales adaptados al impacto cr√≠tico.                 | M√©tricas que no afectan al usuario final.         |

---

## üìä **Resumen de la Estrategia de Alertas y SRE**

- **üö® Detecci√≥n proactiva:** Las alertas y umbrales est√°n dise√±ados para actuar antes de que los problemas impacten a los usuarios.  
- **üìà M√©tricas alineadas al negocio:** Los SLIs/SLOs garantizan el cumplimiento de objetivos estrat√©gicos.  
- **‚öôÔ∏è Resiliencia operativa:** La configuraci√≥n de alertas y escalado autom√°tico permite mantener un servicio confiable y de alto rendimiento.  

---

## 5.3 üéØ **SLIs y SLOs Propuestos**

Los **SLIs (Service Level Indicators)** y **SLOs (Service Level Objectives)** definen los compromisos de rendimiento y disponibilidad del sistema.

### üìè **Service Level Indicators (SLIs)**

- **Latencia de la API:** Tiempo de respuesta promedio de la API.  
- **Tasa de errores:** Porcentaje de solicitudes fallidas (errores 5xx).  
- **Disponibilidad del sistema:** Porcentaje de tiempo que la API est√° disponible.

### ‚úÖ **Service Level Objectives (SLOs)**

| **Indicador**           | **Objetivo (SLO)**                      |
|------------------------|----------------------------------------|
| **Disponibilidad**      | ‚â• **99.9%** de tiempo activo mensual.  |
| **Latencia de la API**  | ‚â§ **500 ms** en el 95% de las peticiones. |
| **Tasa de errores**     | ‚â§ **1%** de respuestas con error.      |

---

## 5.4 üõ°Ô∏è **Propuestas para Mejorar la Resiliencia del Sistema**

Para mitigar posibles riesgos y mejorar la disponibilidad, se proponen las siguientes medidas:

### üìà **Escalabilidad Autom√°tica (Auto Scaling):**  
- Configurar **Cloud Run** para autoescalar en funci√≥n de la demanda.  
- Ajustar particionamiento y clustering en **BigQuery** para optimizar las consultas.

### üîÑ **Implementar Retrys Exponenciales:**  
- Configurar reintentos autom√°ticos en **Pub/Sub** para manejar fallos transitorios.  
- Incorporar circuit breakers en la API.

### üõ†Ô∏è **Validaci√≥n de Datos:**  
- Validar la estructura de los mensajes antes de insertarlos en **BigQuery**.

### üè∑Ô∏è **Etiquetado de Recursos:**  
- Uso de etiquetas para segmentar recursos cr√≠ticos y aplicar reglas espec√≠ficas de monitoreo.

---

## 5.5 üöß **Dificultades y Limitaciones de Observabilidad**

Si no se abordan adecuadamente los desaf√≠os de escalabilidad y monitoreo, podr√≠an surgir los siguientes problemas:

- **Alertas Falsas Positivas:** Alertas mal configuradas que saturan los canales de notificaci√≥n.  
- **Falta de Visibilidad:** M√©tricas incompletas o dispersas dificultan la identificaci√≥n de cuellos de botella.  
- **Escalabilidad del Monitoreo:** Al escalar a m√∫ltiples instancias, puede volverse complejo gestionar las m√©tricas y alertas.  
- **Costos Elevados:** Exceso de monitoreo puede generar costos innecesarios si no se optimizan los recursos.

**üîë Soluci√≥n:**  
- Configurar correctamente los umbrales de alertas.  
- Implementar dashboards agregados por ambiente.  
- Uso eficiente de los recursos para balancear costos y rendimiento.

---

## ‚úàÔ∏è **Conclusi√≥n**

La implementaci√≥n de alertas proactivas, junto con m√©tricas clave y objetivos claros de disponibilidad y rendimiento, garantizan la **resiliencia**, **escalabilidad** y **fiabilidad** del sistema. Las acciones correctivas y preventivas propuestas mitigan los posibles riesgos, asegurando la continuidad operativa.

---

```
        __|__
--@--@--(_)--@--@--
```

---


# üéâ **¬°Gracias por la Oportunidad!** üôå

Quiero expresar mi m√°s sincero agradecimiento por la oportunidad de participar en el **LATAM Airlines DevSecOps/SRE Challenge**. üåé‚úàÔ∏è

Muchas gracias por recibir mi desaf√≠o, en el van muchas horas de esfuerzo y motivaci√≥n por la oportunidad de formar parte del equipo.

Este proyecto ha sido una experiencia incre√≠ble, en la que he invertido muchas horas llenas de **motivaci√≥n**, **aprendizaje** e **ilusi√≥n**. Cada l√≠nea de c√≥digo, cada despliegue y cada prueba fueron pensados con el compromiso de entregar una soluci√≥n robusta ,a la altura del desaf√≠o y la compa√±ia. üíª ‚úàÔ∏è‚úàÔ∏è‚úàÔ∏è‚úàÔ∏è‚úàÔ∏è‚úàÔ∏è

¬°Estoy emocionado por todo lo aprendido y por seguir creciendo en el mundo de la tecnolog√≠a! üåê

---

## üîß‚ú®‚úàÔ∏è **¬°Nos vemos en las nubes!** ‚òÅÔ∏è
--- 
üìÇ Repositorio
üîó https://github.com/fernachbauer/latam-challenge

üìß Contacto
Nombre: Fernando Nachbauer R
Correo: fernachbauer@gmail.com
---